{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aif360.metrics.ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "sys.path.insert(1, \"../\")  \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*** ClassificationMetric ***\\n \\nClass for computing metrics based on TWO BinaryLabelDatasets.\\n\\nThe first dataset is the original one and the second is the output of the classification transformer (or similar).\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.datasets import GermanDataset, StructuredDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "'''\n",
    "*** ClassificationMetric ***\n",
    " \n",
    "Class for computing metrics based on TWO BinaryLabelDatasets.\n",
    "\n",
    "The first dataset is the original one and the second is the output of the classification transformer (or similar).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ClassificationMetric\n",
    "\n",
    "###### Parameters:\n",
    "<li> dataset (BinaryLabelDataset) – Dataset containing ground-truth labels.</li>\n",
    "<li> classified_dataset (BinaryLabelDataset) – Dataset containing predictions.</li>\n",
    "<li> privileged_groups (list(dict)) – Privileged groups. Format is a list of dicts where the keys are protected_attribute_names and the values are values in protected_attributes. Each dict element describes a single group. </li>\n",
    "<li> unprivileged_groups (list(dict)) – Unprivileged groups in the same format as privileged_groups.</li>\n",
    "\n",
    "###### Raises:\n",
    "<li> TypeError – dataset and classified_dataset must be BinaryLabelDataset types.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset containing ground-truth labels.\n",
    "german = GermanDataset(\n",
    "    label_name='credit',\n",
    "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
    "                                                 # attribute for \"sex\" which we do not\n",
    "                                                 # consider in this evaluation\n",
    "    privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "    \n",
    "    features_to_drop=['personal_status', 'sex']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean        1.300000\n",
      "std         0.458487\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max         2.000000\n",
      "Name: credit, dtype: float64\n",
      "count    1000.000000\n",
      "mean        1.498000\n",
      "std         0.500246\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max         2.000000\n",
      "Name: credit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = StructuredDataset.convert_to_dataframe(german)\n",
    "\n",
    "print(df[0]['credit'].describe())\n",
    "\n",
    "for i in range(len(df[0]['credit'])):\n",
    "    df[0]['credit'][i] = random.randint(1,2)\n",
    "\n",
    "print(df[0]['credit'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        1.498000\n",
       "std         0.500246\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         2.000000\n",
       "Name: credit, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset containing predictions.\n",
    "german1 = StandardDataset(df[0], label_name='credit', favorable_classes=[1], protected_attribute_names= ['age'], privileged_classes=[lambda x: x >= 1])\n",
    "\n",
    "df1 = StructuredDataset.convert_to_dataframe(german1)\n",
    "\n",
    "df1[0]['credit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "german1.align_datasets(german) #Align the other dataset features, labels and protected_attributes to this dataset.\n",
    "\n",
    "p = [{'age': 1}] #, {'sex': 0}] \n",
    "u = [{'age': 0}]\n",
    "\n",
    "cm = ClassificationMetric(german, german1, unprivileged_groups=u, privileged_groups=p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the number of true/false positives/negatives, optionally conditioned on protected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 339.0, 'FP': 163.0, 'TN': 137.0, 'FN': 361.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.binary_confusion_matrix(privileged=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 301.0, 'FP': 129.0, 'TN': 110.0, 'FN': 311.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.binary_confusion_matrix(privileged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GTP': 339.0, 'GFP': 163.0, 'GTN': 137.0, 'GFN': 361.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.generalized_binary_confusion_matrix() #Compute the number of generalized true/false positives/negatives, optionally conditioned on protected attributes. Generalized counts are based on scores and not on the hard predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute various performance measures on the dataset, optionally conditioned on protected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPR': 0.48428571428571426,\n",
       " 'TNR': 0.45666666666666667,\n",
       " 'FPR': 0.5433333333333333,\n",
       " 'FNR': 0.5157142857142857,\n",
       " 'GTPR': 0.48428571428571426,\n",
       " 'GTNR': 0.45666666666666667,\n",
       " 'GFPR': 0.5433333333333333,\n",
       " 'GFNR': 0.5157142857142857,\n",
       " 'PPV': 0.6752988047808764,\n",
       " 'NPV': 0.2751004016064257,\n",
       " 'FDR': 0.3247011952191235,\n",
       " 'FOR': 0.7248995983935743,\n",
       " 'ACC': 0.476}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.performance_measures(privileged=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPR': 0.4918300653594771,\n",
       " 'TNR': 0.4602510460251046,\n",
       " 'FPR': 0.5397489539748954,\n",
       " 'FNR': 0.5081699346405228,\n",
       " 'GTPR': 0.4918300653594771,\n",
       " 'GTNR': 0.4602510460251046,\n",
       " 'GFPR': 0.5397489539748954,\n",
       " 'GFNR': 0.5081699346405228,\n",
       " 'PPV': 0.7,\n",
       " 'NPV': 0.26128266033254155,\n",
       " 'FDR': 0.3,\n",
       " 'FOR': 0.7387173396674585,\n",
       " 'ACC': 0.48296122209165687}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.performance_measures(privileged=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias amplification is the difference in smoothed EDF between the classifier and the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.33302546142046585"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.differential_fairness_bias_amplification(concentration=1.0) #Positive values mean the bias increased due to the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized entropy index is proposed as a unified individual and group fairness measure in b_i = hat{y}_i - y_i + 1. https://las.inf.ethz.ch/files/speicher2018a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm0 = ClassificationMetric(german, german, unprivileged_groups=u, privileged_groups=p)\n",
    "\n",
    "cm0.generalized_entropy_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37686021853097906"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.generalized_entropy_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
