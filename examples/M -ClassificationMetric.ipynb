{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aif360.metrics.ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "sys.path.insert(1, \"../\")  \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*** ClassificationMetric ***\\n \\nClass for computing metrics based on TWO BinaryLabelDatasets.\\n\\nThe first dataset is the original one and the second is the output of the classification transformer (or similar).\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.datasets import GermanDataset, StructuredDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "'''\n",
    "*** ClassificationMetric ***\n",
    " \n",
    "Class for computing metrics based on TWO BinaryLabelDatasets.\n",
    "\n",
    "The first dataset is the original one and the second is the output of the classification transformer (or similar).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ClassificationMetric\n",
    "\n",
    "###### Parameters:\n",
    "<li> dataset (BinaryLabelDataset) – Dataset containing ground-truth labels.</li>\n",
    "<li> classified_dataset (BinaryLabelDataset) – Dataset containing predictions.</li>\n",
    "<li> privileged_groups (list(dict)) – Privileged groups. Format is a list of dicts where the keys are protected_attribute_names and the values are values in protected_attributes. Each dict element describes a single group. </li>\n",
    "<li> unprivileged_groups (list(dict)) – Unprivileged groups in the same format as privileged_groups.</li>\n",
    "\n",
    "###### Raises:\n",
    "<li> TypeError – dataset and classified_dataset must be BinaryLabelDataset types.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset containing ground-truth labels.\n",
    "german = GermanDataset(\n",
    "    label_name='credit',\n",
    "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
    "                                                 # attribute for \"sex\" which we do not\n",
    "                                                 # consider in this evaluation\n",
    "    privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "    \n",
    "    features_to_drop=['personal_status', 'sex']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean        1.300000\n",
      "std         0.458487\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max         2.000000\n",
      "Name: credit, dtype: float64\n",
      "count    1000.000000\n",
      "mean        1.498000\n",
      "std         0.500246\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max         2.000000\n",
      "Name: credit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = StructuredDataset.convert_to_dataframe(german)\n",
    "\n",
    "print(df[0]['credit'].describe())\n",
    "\n",
    "for i in range(len(df[0]['credit'])):\n",
    "    df[0]['credit'][i] = random.randint(1,2)\n",
    "\n",
    "print(df[0]['credit'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        1.498000\n",
       "std         0.500246\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         2.000000\n",
       "Name: credit, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset containing predictions.\n",
    "german1 = StandardDataset(df[0], label_name='credit', favorable_classes=[1], protected_attribute_names= ['age'], privileged_classes=[lambda x: x >= 1])\n",
    "\n",
    "df1 = StructuredDataset.convert_to_dataframe(german1)\n",
    "\n",
    "df1[0]['credit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#german = german.align_datasets(german1) #Align the other dataset features, labels and protected_attributes to this dataset.\n",
    "\n",
    "p = [{'age': 1}] #, {'sex': 0}] \n",
    "u = [{'age': 0}]\n",
    "\n",
    "cm = ClassificationMetric(german, german1, unprivileged_groups=u, privileged_groups=p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the number of true/false positives/negatives, optionally conditioned on protected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 348.0, 'FP': 154.0, 'TN': 146.0, 'FN': 352.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.binary_confusion_matrix(privileged=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 304.0, 'FP': 123.0, 'TN': 116.0, 'FN': 308.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.binary_confusion_matrix(privileged=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute various performance measures on the dataset, optionally conditioned on protected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPR': 0.49714285714285716,\n",
       " 'TNR': 0.4866666666666667,\n",
       " 'FPR': 0.5133333333333333,\n",
       " 'FNR': 0.5028571428571429,\n",
       " 'GTPR': 0.49714285714285716,\n",
       " 'GTNR': 0.4866666666666667,\n",
       " 'GFPR': 0.5133333333333333,\n",
       " 'GFNR': 0.5028571428571429,\n",
       " 'PPV': 0.6932270916334662,\n",
       " 'NPV': 0.2931726907630522,\n",
       " 'FDR': 0.30677290836653387,\n",
       " 'FOR': 0.7068273092369478,\n",
       " 'ACC': 0.494}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.performance_measures(privileged=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPR': 0.49673202614379086,\n",
       " 'TNR': 0.48535564853556484,\n",
       " 'FPR': 0.5146443514644351,\n",
       " 'FNR': 0.5032679738562091,\n",
       " 'GTPR': 0.49673202614379086,\n",
       " 'GTNR': 0.48535564853556484,\n",
       " 'GFPR': 0.5146443514644351,\n",
       " 'GFNR': 0.5032679738562091,\n",
       " 'PPV': 0.711943793911007,\n",
       " 'NPV': 0.27358490566037735,\n",
       " 'FDR': 0.28805620608899296,\n",
       " 'FOR': 0.7264150943396226,\n",
       " 'ACC': 0.4935370152761457}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.performance_measures(privileged=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias amplification is the difference in smoothed EDF between the classifier and the original dataset. Positive values mean the bias increased due to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3742733430617343"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.differential_fairness_bias_amplification(concentration=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
